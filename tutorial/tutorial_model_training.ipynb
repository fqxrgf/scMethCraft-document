{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f73dc88",
   "metadata": {},
   "source": [
    "# Environment Setup and Library Import\n",
    "Import necessary modules and set up the Python environment for methylation analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acad20ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:58:54.571749Z",
     "start_time": "2025-05-31T09:58:52.014839Z"
    }
   },
   "outputs": [],
   "source": [
    "from scMethCraft.model.scmethcraft_model import *\n",
    "from scMethCraft.model.utils_model import *\n",
    "from scMethCraft.model.scmethcraft_trainning import *\n",
    "from scMethCraft.model.compute_pos import return_pos\n",
    "\n",
    "import scMethCraft.benchmark.methyimp as mp\n",
    "import pandas as pd\n",
    "import sklearn.metrics as metrics\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a67869",
   "metadata": {},
   "source": [
    "# Seed Initialization\n",
    "Set random seeds for reproducibility across different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54c7e5ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:58:54.580388Z",
     "start_time": "2025-05-31T09:58:54.574254Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=11):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e31b8",
   "metadata": {},
   "source": [
    "# Parameter Configuration\n",
    "Set key parameters for the model and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b34dae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:58:54.604673Z",
     "start_time": "2025-05-31T09:58:54.581812Z"
    }
   },
   "outputs": [],
   "source": [
    "seq_length = 10000\n",
    "kmer_k = 8\n",
    "work_dir = './'\n",
    "device = \"cuda:2\"\n",
    "dataset = \"Test_dataset\"\n",
    "input_path = f\"../project/sample_data/genome/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf48952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T16:10:27.287993Z",
     "start_time": "2025-05-26T16:10:27.273246Z"
    }
   },
   "source": [
    "# Data Loading and Preparation\n",
    "Load and prepare sequence data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0850b98f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:59:16.638622Z",
     "start_time": "2025-05-31T09:58:54.607010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " UserWarning:/prog/cabins/sccasimp/methyimp/project/scMethCraft/model/scmethcraft_trainning.py:44: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n"
     ]
    }
   ],
   "source": [
    "train_onehot,train_kmer,pos = load_seq(input_path,\"all_seqs.h5\",False,\"both\")\n",
    "train_pos = return_pos(pos)\n",
    "train_state = load_state(input_path,\"m_all.npy\",False)\n",
    "train_data = MethyDataset(train_onehot,train_kmer,train_state,train_pos)\n",
    "cell = train_state.shape[1]\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=True,num_workers = 10, pin_memory = True)\n",
    "test_dataloader = torch.utils.data.DataLoader(train_data,batch_size=64,shuffle=False,num_workers = 10, pin_memory = True)\n",
    "del train_onehot,train_kmer,train_state,train_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19165ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-26T16:10:47.558277Z",
     "start_time": "2025-05-26T16:10:47.546822Z"
    },
    "code_folding": []
   },
   "source": [
    "# Model Initialization\n",
    "Initialize the two-part scMethCraft model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cac1f9ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:59:17.606178Z",
     "start_time": "2025-05-31T09:59:16.640643Z"
    }
   },
   "outputs": [],
   "source": [
    "scMethCraft_part1 = Sequence_extraction(cell,K=kmer_k,genomic_seq_length = seq_length).to(device)\n",
    "scMethCraft_part2 = Similarity_weighting(cell,dropout_rate=0.5).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb18d4c",
   "metadata": {},
   "source": [
    "# Training Setup\n",
    "Configure loss function, optimizer, and training parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6579ff08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:59:17.612450Z",
     "start_time": "2025-05-31T09:59:17.608032Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
    "learning_rate = 1e-2\n",
    "optimizer1 = torch.optim.Adam(scMethCraft_part1.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.Adam(scMethCraft_part2.parameters(), lr=learning_rate)\n",
    "epoch = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71026897",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Execute the training loop for 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a79356d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:59:45.361134Z",
     "start_time": "2025-05-31T09:59:17.614024Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------epoch  1 -------\n",
      "Loss1: 29.319700181484222, Loss2: 34.97466903924942\n",
      "-------epoch  2 -------\n",
      "Loss1: 26.51578989624977, Loss2: 30.092981934547424\n",
      "-------epoch  3 -------\n",
      "Loss1: 24.343131631612778, Loss2: 28.82106864452362\n",
      "-------epoch  4 -------\n",
      "Loss1: 21.022560745477676, Loss2: 28.636630177497864\n",
      "-------epoch  5 -------\n",
      "Loss1: 18.95030552148819, Loss2: 28.614707946777344\n"
     ]
    }
   ],
   "source": [
    "train_losses1 = []\n",
    "train_losses2 = []\n",
    "for i in range(epoch):\n",
    "    print(\"-------epoch  {} -------\".format(i+1))\n",
    "    # 训练步骤\n",
    "    MethyBasset_part1.train()\n",
    "    train_loss1 = 0 \n",
    "    train_loss2 = 0 \n",
    "    for step,[onehot, targets, kmer,pos] in enumerate(train_dataloader): \n",
    "        \n",
    "        onehot = onehot.to(device).float()\n",
    "        kmer = kmer.to(device).float()\n",
    "        pos = pos.to(device).float()\n",
    "        targets = targets.to(device).float()\n",
    "        \n",
    "        outputs_part1 = MethyBasset_part1(onehot,kmer,pos).float()\n",
    "        fla = nn.Flatten(0)\n",
    "        \n",
    "        reconstructed_matrix = torch.sigmoid(outputs_part1)\n",
    "        imputed_matrix = reconstructed_matrix*(torch.isnan(targets)).int()+torch.nan_to_num(targets)\n",
    "    \n",
    "        outputs_part1 = fla(outputs_part1)\n",
    "        targets = fla(targets)\n",
    "        \n",
    "        is_loss = ~torch.isnan(targets)\n",
    "       \n",
    "        loss1 = loss_fn(outputs_part1[is_loss], targets[is_loss])\n",
    "        train_loss1 += loss1.item()\n",
    "        \n",
    "        optimizer1.zero_grad()\n",
    "        loss1.backward()\n",
    "        optimizer1.step()\n",
    "        \n",
    "        outputs_part2 = MethyBasset_part2(imputed_matrix.detach())\n",
    "        outputs_part2 = fla(outputs_part2)\n",
    "        loss2 = loss_fn(outputs_part2[is_loss], targets[is_loss])\n",
    "        train_loss2 += loss2.item()\n",
    "        \n",
    "        # 优化器\n",
    "\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        loss2.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        train_step = len(train_dataloader)*i+step+1\n",
    "        \n",
    "    train_losses1.append(train_loss1)    \n",
    "    train_losses2.append(train_loss2)   \n",
    "    print(f\"Loss1: {train_loss1}, Loss2: {train_loss2}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d0a7f",
   "metadata": {},
   "source": [
    "# Execute Model Saving\n",
    "Run the output function to save trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70ff4cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:59:45.480899Z",
     "start_time": "2025-05-31T09:59:45.363187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "output_model(scMethCraft_part1,scMethCraft_part2,savepath = f\"../project/sample_data/output/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "methyimp",
   "language": "python",
   "name": "methyimp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
